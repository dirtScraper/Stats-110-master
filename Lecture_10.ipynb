{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 10: Expectation Continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Proof of Linearity (discrete case)\n",
    "\n",
    "Let $T = X + Y$, and show that $\\mathbb{E}(T) = \\mathbb{E}(X) + \\mathbb{E}(Y)$.\n",
    "\n",
    "We will also show that $\\mathbb{E}(cX) = c \\mathbb{E}(X)$.\n",
    "\n",
    "In general, we'd like to be in a position where\n",
    "\n",
    "\\begin{align}\n",
    "  \\sum_{t} t P(T=t) \\stackrel{?}{=} \\sum_{x} x P(X=x) + \\sum_{y} y P(Y=y)\n",
    "\\end{align}\n",
    "\n",
    "so, let's try attacking this from the l.h.s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/L1001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the image above of a discrete r.v. in Pebble World, note that\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbb{E}(X) &= \\sum_{x} x P(X=x) & &\\text{grouping the pebbles per X value; weighted average} \\\\\n",
    "  &= \\sum_{s}X(s)P(\\{s\\}) & &\\text{ungrouped; sum each pebble separately} \\\\\n",
    "  \\\\\n",
    "  \\\\\n",
    "  \\Rightarrow \\mathbb{E}(T) &= \\sum_{s} (X+Y)(s)P(\\{s\\}) \\\\\n",
    "  &= \\sum_{s}X(s)P(\\{s\\}) + \\sum_{s}Y(s)P(\\{s\\}) \\\\\n",
    "  &= \\sum_{x} x P(X=x) + \\sum_{y} y P(Y=y) \\\\\n",
    "  &= \\mathbb{E}(X) + \\mathbb{E}(Y) ~~~~ \\blacksquare \\\\\n",
    "  \\\\\n",
    "  \\\\\n",
    "  \\Rightarrow \\mathbb{E}(cX) &= \\sum_{x} cx P(X=x) \\\\\n",
    "  &= c \\sum_{x} x P(X=x) \\\\\n",
    "  &= c \\mathbb{E}(X) ~~~~ \\blacksquare\n",
    "\\end{align}\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Binomial Distribution\n",
    "\n",
    "### Description\n",
    "\n",
    "A misnomer: this distribution is actually non-negative, and not binomial, either.\n",
    "\n",
    "The Negative Binomial is a generalization of the Geometric distribution, where we have a series of independent $Bern(p)$ trials and we want to know # failures before the $r^{\\text{th}}$ success.\n",
    "\n",
    "We can codify this using a bit string:\n",
    "\n",
    "\\begin{align}\n",
    "  & \\text{1000100100001001} & \\text{0 denotes failure, 1 denotes success} & \\\\\n",
    "  & r = 5 \\\\\n",
    "  & n = 11 & \\text{failures} \n",
    "\\end{align}\n",
    "\n",
    "Note that the very last bit position is, of course, a success.\n",
    "\n",
    "Note also that we can permutate the preceding $r-1$ successes amongst the $n+r-1$ slots that come before that final $r^{\\text{th}}$ success.\n",
    "\n",
    "### Notation\n",
    "\n",
    "$X \\sim NB(r,p)$\n",
    "\n",
    "### Parameters\n",
    "\n",
    "* $r$ - the total number of successes before we stop counting\n",
    "* $p$ - probability of success\n",
    "\n",
    "\n",
    "### Probability mass function\n",
    "\n",
    "\\begin{align}\n",
    "  P(X=n) &= \\binom{n+r-1}{r-1}  p^r (1-p)^n & &\\text{for } n = 0,1,2,\\dots\\\\\n",
    "  &= \\binom{n+r-1}{n}  p^r (1-p)^n & &\\text{or conversely}\\\\\n",
    "\\end{align}\n",
    "\n",
    "### Expected value\n",
    "\n",
    "Let $X_j$ be the # failures before the $(j-1)^{\\text{st}}$ and $j^{\\text{th}}$ success. Then we could write\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbb{E}(X) &= \\mathbb{E}(X_1 + X_2 + \\dots + X_r) \\\\\n",
    "                &= \\mathbb{E}(X_1) + \\mathbb{E}(X_2) + \\dots + \\mathbb{E}(X_r) & &\\text{by Linearity} \\\\\n",
    "                &= r \\mathbb{E}(X_1) & &\\text{by symmetry} \\\\\n",
    "                &= r \\frac{q}{p} ~~~~ \\blacksquare\n",
    "\\end{align}\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Revisting the Geometric: the First Success Distribution\n",
    "\n",
    "$X \\sim FS(p)$ is the geometric distribution that counts the trials until first success, *including that first success*.\n",
    "\n",
    "Let $Y = X - 1$. \n",
    "\n",
    "Then $Y \\sim Geom(p)$\n",
    "\n",
    "Expected value of $FS(p)$ is\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbb{E}(X) &= E(Y) + 1 \\\\\n",
    "                &= \\frac{q}{p} + 1 \\\\\n",
    "                &= \\boxed{\\frac{1}{p}}\n",
    "\\end{align}\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Putnam Problem\n",
    "\n",
    "Consider a random permutation of $1, 2, 3, \\dots , n$, where $n \\ge 2$.\n",
    "\n",
    "Find expected # local maxima. For example, given the permuation $\\boxed{3} ~~ 2 ~~ 1 ~~ 4 ~~ \\boxed{7} ~~ 5 ~~ \\boxed{6}$ we have 3 local maxima:\n",
    "\n",
    "- $\\boxed{3} \\gt 2$\n",
    "- $4 \\lt \\boxed{7} \\gt 5$\n",
    "- $ 5 \\lt \\boxed{6}$\n",
    "\n",
    "Now, there are 2 kinds of cases we need to consider:\n",
    "\n",
    "- non-edge case: $4 ~~ \\boxed{7} ~~ 5$ has probability of $\\frac{1}{3}$ that the largest number is in the middle position\n",
    "- edge case: in both left-edge $\\boxed{3} ~~ 2$ and right-edge $5 ~~ \\boxed{6}$, the probability that the larger number is in the right position is $\\frac{1}{2}$\n",
    "\n",
    "Let $I_j$ be the indicator r.v. of position $j$ having a local maximum, $1 \\le j \\le n$.\n",
    "\n",
    "Using Linearity, we can say that the expected number of local maxima is given by\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbb{E}(I_j) &= \\mathbb{E}(I_1 + I_2 + \\dots + I_n) \\\\\n",
    "                  &= \\mathbb{E}(I_1) + \\mathbb{E}(I_2) + \\dots + \\mathbb{E}(I_n) & &\\text{by Linearity} \\\\\n",
    "                  &= (n-2) \\frac{1}{3} + 2 \\frac{1}{2} \\\\\n",
    "                  &= \\boxed{\\frac{n+1}{3}}\n",
    "\\end{align}\n",
    "\n",
    "Idiot-checking this, we have:\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbb{E}(I_{n=2}) &= \\frac{2+1}{3} & &\\text{... case where } n=2 \\\\\n",
    "  &= 1 \\\\\n",
    "  \\\\\n",
    "  \\\\\n",
    "  \\mathbb{E}(I_{n=\\infty}) &= \\frac{\\infty+1}{3} & &\\text{... case where } n= \\infty \\\\\n",
    "  &= \\infty \\\\\n",
    "\\end{align}\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## St. Petersburg Paradox\n",
    "\n",
    "Consider a game of chance involving a fair coin. We will flip the coin until the very first heads shows (hypergeometric distribution). \n",
    "\n",
    "- If heads shows on the very first flip, you get $\\$2$.\n",
    "- If the first heads shows on the second flip, you get $\\$4$.\n",
    "- If the first heads shows on the third flip, you get $\\$8$.\n",
    "\n",
    "So you will get $\\$2^n$ if the first heads shows up on the $n^\\text{th}$ trial, including the heads flip.\n",
    "\n",
    "_How much would you be willing to play this game?_\n",
    "\n",
    "Let's tackle this by thinking about the expected number of $\\$\\$\\$$ we stand to make. \n",
    "\n",
    "Given $Y = 2^n$, find $\\mathbb{E}(Y)$:\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbb{E}(Y) &= \\sum_{k=1}^\\infty 2^k \\frac{1}{2^{k-1}} ~ \\frac{1}{2}\\\\\n",
    "                &= \\sum_{k=1}^\\infty 2^k \\frac{1}{2^k}\\\\\n",
    "                &= \\sum_{k=1}^\\infty 1\\\\\n",
    "  \\\\\n",
    "  \\\\\n",
    "  \\mathbb{E}(Y_{k=40}) &= \\sum_{k=1}^{40} 1 \\\\\n",
    "                       &= 40\n",
    "\\end{align}\n",
    "\n",
    "So, the \"paradox\" here is that even if we capped the payout to $2^{40} \\approx \\$1000000000$, Linearity shows us we would only pay $40. It is very hard to grasp this, but the truth is that if you were offered this game at any price, you should take it.\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
